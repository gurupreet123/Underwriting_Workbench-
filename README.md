# Intelligent Underwriting Workbench ğŸ›¡ï¸

**An Agentic AI Coâ€‘Pilot for Commercial Risk Assessment**

---

## ğŸ“Œ Project Overview

The **Intelligent Underwriting Workbench** is an AI-powered application built to solve the "unstructured data overload" problem in commercial insurance underwriting. Rather than spending hours manually reading PDF applications, loss runs and credit reports, this workbench ingests and synthesizes risk data using a Multiâ€‘Agent architecture and produces:

* A consistent **Risk Score (0â€“10)**
* A clear **Recommendation** (Approve / Decline)
* An **Auto-drafted decision letter** with rationale

It is designed for privacy-first local deployment (Ollama) and enforces structured outputs using Pydantic.

---

## ğŸš€ Key Features

* **Robust PDF Ingestion** â€” Custom regex pipeline to repair column/table text extraction.
* **Multiâ€‘Agent Analysis** â€” Parallel Claims, Profile, and External agents for speed and accuracy.
* **Structured Guardrails** â€” Pydantic schemas force LLM responses into reliable JSON.
* **Privacyâ€‘First** â€” Runs locally on Ollama; applicant data never leaves the host.
* **Advanced Analytics** â€” Interactive radar charts and explainability dashboards (Plotly).
* **Automated Decisioning** â€” Auto-draft formal decision letters tailored to flagged risk factors.

---

## ğŸ—ï¸ System Architecture

High-level layers:

1. **Ingress**: Streamlit-based UI â€” upload PDF or paste text.
2. **Application**: Cleaning, text extraction & pre-processing.
3. **Intelligence Engine** (The Brain):

   * **Orchestrator** â€” dispatches tasks to agents (concurrent execution).
   * **Specialist Agents** â€” Claims, Profile, External (each evaluates a focused sub-domain).
   * **Synthesis Manager** â€” merges agent outputs, applies business rules & guidelines (RAG).
4. **Data & Validation**: Pydantic models validate outputs before presenting in UI.
5. **Presentation**: Streamlit dashboard with gauges, radar charts, and a Deep Dive view.

---

## ğŸ§© Technology Stack

* **Frontend**: Streamlit (Python)
* **Orchestration**: LangChain (RunnableParallel for parallel agents)
* **LLM**: Ollama (Llama3 local inference)
* **Validation**: Pydantic
* **Visualization**: Plotly (gauges, radar charts)
* **PDF Parsing**: pypdf + custom regex cleanup

---

## âš™ï¸ Installation & Setup

> Tested on Python 3.10+ and Ollama running locally.

1. Clone the repository

```bash
git clone https://github.com/yourusername/underwriting-workbench.git
cd underwriting-workbench
```

2. Install dependencies

```bash
pip install -r requirements.txt
```

> Ensure `requirements.txt` contains at least:
>
> ```text
> streamlit
> langchain
> langchain-ollama
> pydantic
> plotly
> pypdf
> streamlit-option-menu
> ```

3. Pull the model to Ollama (local)

```bash
ollama pull llama3
```

4. Run the app

```bash
streamlit run app.py
```

---

## ğŸ“¸ Usage

1. **Upload**: Drag & drop a commercial insurance application (PDF) or paste raw text into the Streamlit UI.
2. **Analyze**: Agents run in parallel and extract Claims, Credit, and Legal signals.
3. **Review**: Dashboard displays the aggregated **Risk Score** and a quick decision card.
4. **Deep Dive**: Inspect agent-level reasoning, sources, and the Pydantic-validated JSON.
5. **Act**: Copy the auto-generated decision email/letter for policy communication.

---

## ğŸ›ï¸ Notable Implementation Details

* **Multi-Agent Orchestration**: Use LangChain `RunnableParallel` to run three specialist flows concurrently, then merge results in a Synthesis Manager.
* **Pydantic Contracts**: Define tight schemas for `AgentOutput`, `RiskFactors[]`, and the final `UnderwritingDecision` to avoid hallucinations.
* **PDF Repair Pipeline**: Heuristic regex transforms correct broken column merges from PDF text extraction.
* **Explainability**: Each agent stores a short human-readable rationale and the citations (text spans) it used.
* **Local-Only LLM**: Ollama + Llama3 for local inference and data privacy.

---

## ğŸ”® Roadmap

* **Phase 2**: Connect a Vector DB (e.g., FAISS/Chroma) for full RAG with historical decisions.
* **Phase 3**: Humanâ€‘inâ€‘theâ€‘Loop feedback and supervised fineâ€‘tuning of agent prompts and scoring.
* **Phase 4**: API integration with policy admin & core insurance systems for automated binding.

---

## ğŸ‘¥ Team

* Gurupreet Dhande
* Khushi Dekate
* Arnav Kalambe

---

## ğŸ“„ Suggested Repository Structure

```
underwriting-workbench/
â”œâ”€ app.py                   # Streamlit entrypoint
â”œâ”€ README.md
â”œâ”€ requirements.txt
â”œâ”€ pipelines/
â”‚  â”œâ”€ pdf_cleanup.py
â”‚  â”œâ”€ ingestion.py
â”‚  â””â”€ validators.py         # pydantic models
â”œâ”€ agents/
â”‚  â”œâ”€ claims_agent.py
â”‚  â”œâ”€ profile_agent.py
â”‚  â””â”€ external_agent.py
â”œâ”€ orchestrator/
â”‚  â””â”€ runnables.py         # langchain runnables + parallelism
â”œâ”€ visualizations/
â”‚  â””â”€ charts.py             # plotly radar/gauge helpers
â””â”€ tests/
   â””â”€ test_pipelines.py
```

---

## âœ… Contributing

Contributions are welcome. Please open issues for feature requests or bug reports. For code changes, send a PR with tests and update `requirements.txt` if you add dependencies.

---

## ğŸ“œ License

Specify a license (e.g., MIT) and include a `LICENSE` file in the repo.

---
